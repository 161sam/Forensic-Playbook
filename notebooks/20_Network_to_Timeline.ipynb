{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 20 · Network → Timeline (Synthetic PCAP/JSON Fallback)\n\nWe avoid shipping binary PCAPs. Instead we synthesize a minimal capture or feed JSON to the network module."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Generate a tiny synthetic 'pcap-like' JSON for analysis.\nfrom pathlib import Path\nimport json\n\nlab = Path.cwd() / \"lab_workspace\"\ncase_id = \"lab_demo_case\"\ncase_dir = lab / \"cases\" / case_id\nanalysis_dir = case_dir / \"analysis\" / \"network\"\nanalysis_dir.mkdir(parents=True, exist_ok=True)\n\nsynthetic = {\n    \"packets\": [\n        {\"ts\":\"2025-01-01T00:00:01Z\",\"src\":\"10.0.0.5\",\"dst\":\"1.2.3.4\",\"proto\":\"TCP\",\"dport\":443},\n        {\"ts\":\"2025-01-01T00:00:03Z\",\"src\":\"10.0.0.5\",\"dst\":\"192.168.1.100\",\"proto\":\"TCP\",\"dport\":4444},\n        {\"ts\":\"2025-01-01T00:00:05Z\",\"src\":\"10.0.0.5\",\"dst\":\"8.8.8.8\",\"proto\":\"UDP\",\"dport\":53,\"dns_query\":\"example.com\"}\n    ]\n}\njson_path = analysis_dir / \"synthetic_network.json\"\njson_path.write_text(json.dumps(synthetic, indent=2, sort_keys=True))\njson_path"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Invoke the SDK network module with JSON input (guarded path).\nfrom forensic.modules.analysis.network import NetworkAnalysisModule\nfrom forensic.core.framework import ForensicFramework\n\nfw = ForensicFramework(workspace=Path.cwd() / \"lab_workspace\")\ncase = fw.load_case(\"lab_demo_case\")\nmod = NetworkAnalysisModule()\n\nparams = {\"pcap_json\": str(json_path), \"dry_run\": False}\n\n# Framework may provide execute_module; if not, call module directly\ntry:\n    res = fw.execute_module(\"network\", params=params)\nexcept Exception:\n    res = mod.run(fw, case, params)\n\nprint(type(res))\ntry:\n    import json as _json\n    print(_json.dumps(res.get(\"summary\", {}), indent=2, sort_keys=True)[:800])\nexcept Exception as e:\n    print(\"Summary not available:\", e)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Build a minimal timeline CSV from the synthesized flows"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Produce a minimal CSV timeline based on synthetic events.\nimport csv\nfrom pathlib import Path\n\ntimeline_csv = (Path.cwd() / \"lab_workspace\" / \"cases\" / \"lab_demo_case\" / \"analysis\" / \"network\" / \"synthetic_timeline.csv\")\ntimeline_csv.parent.mkdir(parents=True, exist_ok=True)\nrows = [\n    (\"2025-01-01T00:00:01Z\",\"net\",\"TCP 10.0.0.5 → 1.2.3.4:443\"),\n    (\"2025-01-01T00:00:03Z\",\"net\",\"TCP 10.0.0.5 → 192.168.1.100:4444 (suspicious)\"),\n    (\"2025-01-01T00:00:05Z\",\"dns\",\"Query example.com via 8.8.8.8\")\n]\nwith timeline_csv.open(\"w\", newline=\"\") as f:\n    w = csv.writer(f)\n    w.writerow([\"timestamp\",\"category\",\"detail\"])\n    for r in rows:\n        w.writerow(r)\n(str(timeline_csv), timeline_csv.read_text().splitlines()[:4])"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}